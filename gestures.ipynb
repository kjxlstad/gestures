{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gestures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFkobcqLTJlT38drW2cRCK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjxlstad/gestures/blob/main/gestures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BowUKpYDCrhq"
      },
      "source": [
        "### 1. Connecting the webcam to Google Colab using Javascript\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxb91oH3QuFt",
        "cellView": "code"
      },
      "source": [
        "#@title \n",
        "import base64\n",
        "import html\n",
        "import io\n",
        "import time\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "      div = document.createElement('div');\n",
        "      div.style.background = '#040F0F'\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = '<span style=\"color: #e3b505;\">Status:</span>';\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.color = '#e3b505'\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: #db504a; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) { \n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR19NYPdAeYY"
      },
      "source": [
        "Basically there are two functions we need to use: start_inpu tand take_photo.\n",
        "When running start_input, we open the webcam (make sure you allowed your browser / Google Colab to open your camera) then provide the canvas to put everything captured by the webcam and showed it to our Google Colab output.\n",
        "We can adjust the size of canvas as desired by changing captureCanvas.width and captureCanvas.height.\n",
        "take_photo return JavaScript object containing the image (in bytes) to be processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCW8Z98LOQbD"
      },
      "source": [
        "Code for a decoder, turning javascrip webcam hooks response object into 512 x 512 x RGB array, and a decoder, whichs turns an 512 x 512 x RGBA array into a javascript compatible bitstring, which then is drawn over the cameara image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS1i3bntANn-"
      },
      "source": [
        "def decode(js_reply):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          js_reply: JavaScript object, contain image from webcam\n",
        "    output: \n",
        "          image_array: image array RGB size 512 x 512 from webcam\n",
        "    \"\"\"\n",
        "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\n",
        "    image_array = np.array(image_PIL)\n",
        "\n",
        "    return image_array"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FW1MmooDwLr"
      },
      "source": [
        "def encode(overlay):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          overlayy: image RGBA size 512 x 512 \n",
        "                              contain bounding box and text from yolo prediction, \n",
        "                              channel A value = 255 if the pixel contains drawing properties (lines, text) \n",
        "                              else channel A value = 0\n",
        "    output: \n",
        "          drawing_b64: string, encoded from overlay\n",
        "    \"\"\"\n",
        "\n",
        "    drawing_PIL = Image.fromarray((overlay), 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    drawing_PIL.save(iobuf, format='png')\n",
        "    drawing_bytes = 'data:image/png;base64,{}'.format((str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "    return drawing_bytes"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVOC_nfWOz5a"
      },
      "source": [
        "Here we get calculate the overlay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCLd7eGPcQCn"
      },
      "source": [
        "def insert_into_middle(a, b) :\n",
        "  na = a.shape[0]\n",
        "  nb = b.shape[0]\n",
        "  lower = (na // 2) - (nb // 2)\n",
        "  upper = (na // 2) + (nb // 2)\n",
        "\n",
        "  for i in range(4):\n",
        "    a[lower:upper, lower:upper, i] = b"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTDckTAwCWJN"
      },
      "source": [
        "def get_overlay(frame): \n",
        "    \"\"\"\n",
        "    input: \n",
        "          frame: image array RGB size 512 x 512 from webcam\n",
        "    output: \n",
        "          overlay: image RGBA size 512 x 512 only contain bounding box and text, \n",
        "                              channel A value = 255 if the pixel contains drawing properties (lines, text) \n",
        "                              else channel A value = 0\n",
        "    \"\"\"\n",
        "    overlay = np.zeros([512,512,4], dtype=np.uint8)\n",
        "    \n",
        "    # define region of interest\n",
        "    #roi = frame[128:384, 128:384, :]\n",
        "\n",
        "    #cv2.rectangle(overlay, (128, 128), (384, 384), (141, 142, 142, 255), 0)\n",
        "    \n",
        "    #min_YCrCb = np.array([0,133,77],np.uint8)\n",
        "    #max_YCrCb = np.array([235,173,127],np.uint8)\n",
        "    imageYCrCb = cv2.cvtColor(frame ,cv2.COLOR_RGB2YCR_CB)\n",
        "    #skinRegionYCrCb = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb)\n",
        "    \n",
        "    skinRegionYCrCb = np.empty([512, 512], dtype=np.uint8).fill(0)\n",
        "    out = cv2.bitwise_and(overlay, overlay, mask = skinRegionYCrCb)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy1gLg_WRs2d"
      },
      "source": [
        "Driver code for drawing. It shows the camera output as defined in the javascript code above, and overlays the calucalted image over it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Un3wd4U_YWz",
        "outputId": "51dd827c-0053-429a-c26a-7d636cf9b58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "import cv2\n",
        "start_input()\n",
        "label_html = 'Capturing...'\n",
        "img_data = ''\n",
        "\n",
        "while True:\n",
        "  capture_start = time.time()\n",
        "  js_reply = take_photo(label_html, img_data)\n",
        "  capture_end = time.time()\n",
        "  if not js_reply:\n",
        "    break\n",
        "\n",
        "  webcam_frame = decode(js_reply)\n",
        "  overlay = get_overlay(webcam_frame)\n",
        "  drawing_bytes = encode(overlay)\n",
        "  img_data = drawing_bytes\n"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "      div = document.createElement('div');\n",
              "      div.style.background = '#040F0F'\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = '<span style=\"color: #e3b505;\">Status:</span>';\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.color = '#e3b505'\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: #db504a; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 512; //video.videoWidth;\n",
              "      captureCanvas.height = 512; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function takePhoto(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) { \n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}